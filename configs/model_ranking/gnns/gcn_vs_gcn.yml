experiment_name: 'gcn-vs-gcn'

trainer: class_hybrid_bt
dataset: class_pcba
dataset_dir: /rds/user/xz398/hpc-work/learning-with-class/dataset
num_epochs: 50
batch_size: 512
log_iterations: 1
eval_per_epochs: 1
patience: 10000 # for early stopping etc
loss_func: CLASSHybridBarlowTwinsLoss
loss_params:
  scale_loss: 1
  lambd: 3.9e-3
  self_tri_coeff: 1
  opponent_tri_coeff: 1
  uniformity_reg: 0
  variance_reg: 0
  covariance_reg: 1
num_train: 50000
seed: 0

metrics:
  - batch_variance
  - dimension_covariance
main_metric: loss
collate_function: class_collate

optimizer: Adam
optimizer_params:
  lr: 5.0e-5

optimizer2: Adam
optimizer2_params:
  lr: 5.0e-5

#scheduler_step_per_batch: False
#lr_scheduler: WarmUpWrapper
#lr_scheduler_params:
#  warmup_steps: [700]
#  # parameters of scheduler to run after warmup
#  wrapped_scheduler: ReduceLROnPlateau
#  cooldown: 20
#  factor: 0.6
#  patience: 25
#  min_lr: 1.0e-6
#  threshold: 1.0e-4
#  mode: 'min'
#  verbose: True

# Model parameters
model_type: 'OGBGNN'
model_parameters:
  gnn_type: 'gcn'
  target_dim: 256
  hidden_dim: 64
  num_layers: 4
  dropout: 0.0
  virtual_node: False

# Model parameters
model2_type: 'OGBGNN'
model2_parameters:
  gnn_type: 'gcn'
  target_dim: 256
  hidden_dim: 64
  num_layers: 4
  dropout: 0.0
  virtual_node: False

# continue training from checkpoint:
#checkpoint: runs/PNAReadout_2_layer_03-04_15-29-07/last_checkpoint.pt
